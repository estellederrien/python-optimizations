{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946a1745",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/uncertainty.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954ad02",
   "metadata": {},
   "source": [
    "# <b> Summary </b>\n",
    "1. <b> Production mixe optimization using a binomial probability distribution</b>\n",
    "    - Abstract\n",
    "    - Instance\n",
    "    - Math model\n",
    "    - Cplex solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10949dc7",
   "metadata": {},
   "source": [
    "# <b>1. Production mixe optimization using a binomial probability distribution</b>\n",
    "\n",
    "## <b> Abstract </b>\n",
    "Sometimes, the profits are not too certain, to make a more realistic optimization, which remains linear, we can use the normal law. (Credit: Aaron Stubberfield)\n",
    "\n",
    "Risks are taken into account: Profit estimates may be inaccurate.\n",
    "\n",
    "\n",
    "Read this link from Aaron Stubberfield:\n",
    "https://s3.amazonaws.com/assets.datacamp.com/production/course_8835/slides/chapter4.pdf\n",
    "\n",
    "We take our basic linear program and add the trick of the normal law.\n",
    "The results are therefore different each time the program is reloaded, since the probability is recalculated each time.\n",
    "\n",
    "\n",
    "## <b> Math model  </b>\n",
    "Comin' soon\n",
    "\n",
    "## <b> Python Pulp code </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9b90b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanc_bleu = 72.0\n",
      "charolaise = 8.0\n",
      "salers = 5.0\n",
      "Profit total maximisÃ© =  10065.719730802874\n",
      "Profits probabilistes: -4.323417354043399 12.49118295460734 -18.811620619301557\n"
     ]
    }
   ],
   "source": [
    "# Importer la librairie Pulp sous le pseudo p\n",
    "import pulp as p \n",
    "import random\n",
    "  \n",
    "# ProbabilitÃ©s\n",
    "a, b, c = random.normalvariate(0,25),random.normalvariate(0,25),random.normalvariate(0,25)\n",
    "\n",
    "# CrÃ©er un programme linÃ©aire de maximisation\n",
    "Mon_Probleme = p.LpProblem('maximisation_de_profit_agricole', p.LpMaximize)  \n",
    "\n",
    "# CrÃ©er les variables du problÃ¨me, \n",
    "# On dit que ce sont des variables entiÃ¨res, car on ne peut pas avoir une demi vache.\n",
    "charolaise = p.LpVariable(\"charolaise\", 0, None, p.LpInteger)   \n",
    "blanc_bleu = p.LpVariable(\"blanc_bleu\", 0, None, p.LpInteger)   \n",
    "salers = p.LpVariable(\"salers\", 0, None, p.LpInteger)  \n",
    "\n",
    "# Ecrire la fonction objectif Ã  maximizer qui nous donne un rÃ©sultat en Euros \n",
    "Mon_Probleme +=  (100+a) * charolaise + (110+b) * blanc_bleu + (115+c) * salers\n",
    "\n",
    "# Les contraintes : \n",
    "\n",
    "# nourriture\n",
    "Mon_Probleme += 7 * charolaise + 7 * blanc_bleu + 8 * salers <= 600\n",
    "\n",
    "# eau\n",
    "Mon_Probleme += 4.5* charolaise + 9 * blanc_bleu + 3 * salers <= 700\n",
    "\n",
    "# RÃ©soudre\n",
    "Mon_Probleme.solve()\n",
    "# On imprime les variables qui ont leur valeur optimisÃ©es\n",
    "for v in Mon_Probleme.variables():\n",
    "    print(v.name, \"=\", v.varValue)\n",
    "# La valeur de la fonction objective optimisÃ©e est imprimÃ©e Ã  l'Ã©cran\n",
    "print(\"Profit total maximisÃ© = \", p.value(Mon_Probleme.objective))\n",
    "\n",
    "print(\"Profits probabilistes:\",a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6351035",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43621413",
   "metadata": {},
   "source": [
    "# <b> Links :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846c314",
   "metadata": {},
   "source": [
    "Comin' soon\n",
    "\n",
    "Ali Papi Rad :\n",
    "\n",
    "ğŸ“š ğ—•ğ—²ğ˜€ğ˜ ğ—¥ğ—²ğ—³ğ—²ğ—¿ğ—²ğ—»ğ—°ğ—²ğ˜€ ğ—¼ğ—³ ğ—¢ğ—½ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ˜‚ğ—»ğ—±ğ—²ğ—¿ ğ—¨ğ—»ğ—°ğ—²ğ—¿ğ˜ğ—®ğ—¶ğ—»ğ˜ğ˜†\n",
    "\n",
    "Recently, I introduced ğŸğŸ“ + ğŸ ğ“ğ¨ğ© ğ€ğ©ğ©ğ«ğ¨ğšğœğ¡ğğ¬ ğ­ğ¨ ğğ©ğ­ğ¢ğ¦ğ¢ğ³ğšğ­ğ¢ğ¨ğ§ ğ®ğ§ğğğ« ğ”ğ§ğœğğ«ğ­ğšğ¢ğ§ğ­ğ² (here: https://lnkd.in/d5iBxFJJ). As promised, reflecting on my own experience and after gathering feedback from my students, Iâ€™m excited to disclose the resources that have truly elevated our learning journeys. If youâ€™ve discovered a resource not on this list thatâ€™s made a real insight for you, Iâ€™d love to hear about it in the comments!\n",
    "\n",
    "\n",
    "âœ… Stochastic Programming (SP)\n",
    "[1] Birge et al.â€¯(2011).â€¯Introduction to Stochastic Programming.â€¯Springerâ€¯Sci.â€¯&â€¯Bus.â€¯Media\n",
    "[2] Shapiro et al.â€¯(2021).â€¯Lectures on Stochastic Programming: Modeling and Theory.â€¯SIAM\n",
    "\n",
    "âœ… Conditional Valueâ€‘atâ€‘Risk (CVaR) Optimization\n",
    "[3] Sarykalin et al.â€¯(2008).â€¯Valueâ€‘atâ€‘Risk vs. Conditional Valueâ€‘atâ€‘Risk in Risk Management and Optimization.â€¯INFORMS\n",
    "\n",
    "âœ… Chanceâ€‘Constrained Programming (CCP)\n",
    "[4] Miller, B. L., & Wagner, H. M. (1965). Chance-constrained programming with joint constraints. Operations research, 13(6), 930-945.\n",
    "\n",
    "âœ… Sample Average Approximation (SAA)\n",
    "[5] Kim et al.â€¯(2014).â€¯A Guide to Sample Average Approximation.â€¯Handb.â€¯Simul.â€¯Optim.\n",
    " [6] Pagnoncelli et al.â€¯(2009).â€¯Sample Average Approximation Method for Chance Constrained Programming: Theory and Applications.â€¯J.â€¯Optim.â€¯Theoryâ€¯Appl.\n",
    "\n",
    "âœ… Robust Optimization (RO)\n",
    "[7] Bertsimas et al.â€¯(2011).â€¯Theory and Applications of Robust Optimization.â€¯SIAMâ€¯Rev.\n",
    "[8] Gorissen et al.â€¯(2015).â€¯A Practical Guide to Robust Optimization.â€¯Omega\n",
    "[9] Gabrel et al.â€¯(2014).â€¯Recent Advances in Robust Optimization: An Overview.â€¯Eur.â€¯J.â€¯Oper.â€¯Res.\n",
    "\n",
    "\n",
    "âœ… Distributionally Robust Optimization (DRO)\n",
    "[10] Van Parys et al.â€¯(2021).â€¯From Data to Decisions: Distributionally Robust Optimization Is Optimal.â€¯Manag.â€¯Sci.\n",
    "[11] Delage et al.â€¯(2010).â€¯Distributionally Robust Optimization Under Moment Uncertainty with Application to Dataâ€‘Driven Problems.â€¯Oper.â€¯Res.\n",
    "[12] Mohajerinâ€¯Esfahani et al.â€¯(2018).â€¯Dataâ€‘Driven Distributionally Robust Optimization Using the Wasserstein Metric: Performance Guarantees and Tractable Reformulations.â€¯Math.â€¯Program.\n",
    "[13] Rahimian et al.â€¯(2022).â€¯Frameworks and Results in Distributionally Robust Optimization.â€¯Openâ€¯J.â€¯Math.â€¯Optim."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
