{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf119751",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/markov.png\"  width=\"500\">\n",
    "</div>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Wikipedia quote : \n",
    "In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" \n",
    "\n",
    "datacamp quote: \n",
    "Markov chains have prolific use in mathematics. They are widely used in economics, game theory, \n",
    "in communication theory, genetics and finance. \n",
    "\n",
    "They arise widely in especially Bayesian statistical and information theoretical contexts. \n",
    "When dealing with real-world problems, they are used to postulate solutions to study cruise control systems \n",
    "in motor vehicles, queues or queues of customers arriving at an airport, currency exchange rates, etc. \n",
    "\n",
    "The algorithm known as PageRank, which was originally proposed for the Internet search engine Google, is based on a process \n",
    "of Markov. Reddit's Subreddit Simulator is a fully automated subreddit that generates random submissions and comments \n",
    "using Markov chains, so cool!\n",
    "\n",
    "you only need to know the current state to determine the next state\n",
    "\n",
    "\n",
    "## Summary \n",
    "\n",
    "1. <b>Predict how many people will move from Lausanne to Geneva</b>\n",
    "    - Instance\n",
    "    - Python code\n",
    "2. <b>Predict the weather based on current weather</b>\n",
    "    - Instance\n",
    "    - Python code\n",
    "3. <b>Predict what a lazy dog will do</b>\n",
    "    - Instance\n",
    "    - Python code\n",
    "4. <b>Predict the path of a mouse</b>\n",
    "    - Instance\n",
    "    - Python code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd7c1",
   "metadata": {},
   "source": [
    "# 1. Chaine de markov discrète à 2 états  :\n",
    "\n",
    "On veut avoir des prévisions des déménagements, en fonction du nombre d'états dans le temps .\n",
    "\n",
    "\n",
    "Source : \n",
    "Youtube PROMATH\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=6Hgqs7T0_1M\n",
    "\n",
    "https://www.youtube.com/channel/UC2flwAftkypBx2gLIamxwqg/videos\n",
    "\n",
    "https://stackoverflow.com/questions/52490184/raising-a-matrix-to-the-nth-power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ebdd04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice à la puissance [[0.562 0.438]\n",
      " [0.219 0.781]]\n",
      " Probabilité évolution de la population:  [2876. 7124.]\n"
     ]
    }
   ],
   "source": [
    "# 0. On charge la librairie\n",
    "import numpy as np\n",
    "\n",
    "# 1. En introduction, On Définit notre fonction qui va calculer une puissance d'une matrice de transition\n",
    "def matrixMul(a, n):\n",
    "    if(n <= 1):\n",
    "        return a\n",
    "    else:\n",
    "        return np.matmul(matrixMul(a, n-1), a)\n",
    "\n",
    "# 2. On crée la ** matrice de transition ** de notre graphe markov discret, celle ci comprends la probabilité de passer d'un état à un autre.\n",
    "\"\"\" \n",
    "La probabilité  de rester à Lausanne est de  : 0.8 \n",
    "La probabilité  de déménagement  de Lausanne à Genève est de  : 0.2 \n",
    "La probabilité  de déménagement  de Genève à Lausanne: 0.1 \n",
    "La probabilité  de rester  à Genève  est de : 0.9  \n",
    "\"\"\"\n",
    "transition_matrix = [[0.8,0.2], [0.1,0.9]]\n",
    "\n",
    "# 3. On précise le nombre d'états qui va nous donner notre probabilité.\n",
    "nombre_etats = 3\n",
    "\n",
    "# 4. On calcule notre matrice à la puissance nombre_etats\n",
    "transition_matrix_power = matrixMul(transition_matrix,nombre_etats)\n",
    "\n",
    "print(\"Matrice à la puissance\",transition_matrix_power )\n",
    "\n",
    "# 5. On crée le ** vecteur de probabilités de l'état initial **\n",
    "# 20% de la popuplation est sur Lausanne et 80% sur Genève, on peut aussi le mettre n personnes\n",
    "probabilite_0 = np.array([2000,8000]) \n",
    "\n",
    "# 6. On calcule les probabilités de l'état du système en fonction du nombre de temps.\n",
    "\n",
    "\"\"\" \n",
    "Etat du système après une période de temps  = P1 = probabilité_0 . transition_matrix\n",
    "Etat du système après 2 période de temps  = P2 = probabilité_0 . transition_matrix ** 2\n",
    "Etat du système après 3 période de temps  = P3 = probabilité_0 . transition_matrix ** 3 -> c'est celle qu'on a choisi de calculer.\n",
    "Etat du système après n période de temps  = Pn = probabilité_0 . transition_matrix ** n\n",
    "\"\"\"\n",
    "\n",
    "c = np.dot(probabilite_0,transition_matrix_power) \n",
    "\n",
    "print(\" Probabilité évolution de la population: \",c)\n",
    "# [2876. 7124.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
