{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf119751",
   "metadata": {},
   "source": [
    "# Markov rules\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Wikipedia quote : \n",
    "In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
