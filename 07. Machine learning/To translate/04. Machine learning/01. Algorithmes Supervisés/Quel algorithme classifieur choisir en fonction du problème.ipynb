{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quel algorithme classifieur supervisé choisir en fonction du problème ?\n",
    "\n",
    "Il existe de nombreux algorithmes d'apprentissage automatique. Il n'existe pas d'algorithme de machine unique qui fonctionne le mieux pour tous les types de scénarios. Certains des facteurs qui affectent notre choix de choisir un algorithme d'apprentissage automatique incluent :\n",
    "\n",
    "    Taille des données d'entraînement\n",
    "    Exactitude et/ou interprétabilité\n",
    "    Temps de formation\n",
    "    Linéarité\n",
    "    Nombre de fonctionnalités\n",
    "    Supervisé ou non supervisé\n",
    "\n",
    "Source : https://milena-pa.medium.com/a-comparison-of-machine-learning-algorithms-knn-vs-decision-trees-d6110e08bfea"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <b>L'arbre de décision (Decision tree)</b>\n",
    "\n",
    "Pour classifier un élément, il sert donc de \"questions successives\".\n",
    "Il se constitue d'options successives souvent binaires. \n",
    "\n",
    "On peut bien le visualiser avec python et même en faire un arbre de probabilités avec le bon code.\n",
    "\n",
    "2. <b>Les plus proches voisins ( K-Neighbors)</b>\n",
    "\n",
    "Pour classifier un élément par rapport aux autres, il se sert de la distance mesurée avec ses plus proches voisins.\n",
    "\n",
    "\"Bien que KNN atteigne une grande précision sur l'ensemble de test, il est plus lent et plus coûteux en termes de temps et de mémoire. Il a besoin d'une quantité considérable de mémoire afin de stocker l'ensemble des données d'entraînement pour la prédiction. De plus, étant donné que la distance euclidienne est très sensible aux magnitudes, les caractéristiques de l'ensemble de données avec de grandes magnitudes l'emporteront toujours sur celles avec de petites magnitudes.\n",
    "\n",
    "Enfin, compte tenu de tout ce dont nous avons discuté jusqu'à présent, nous devons garder à l'esprit que KNN n'est pas idéal pour les ensembles de données de grande dimension.\"\"\n",
    "\n",
    "3. <b>Le Bayesien Naïf</b>\n",
    "\"La raison pour laquelle les modèles bayésiens naïfs sont si efficaces est qu'ils apprennent les paramètres en en examinant chaque fonctionnalité individuellement et en collectant des statistiques simples par classe à partir de chaque\n",
    "fonctionnalité.\" O' reilly\n",
    "\n",
    "4. <b>La forêt ( random forest - Ensemble d'arbres de décision)</b>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edb60928ae049011e12e2dc43646b5515922153b602d9d974a622a5d486bbfcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
